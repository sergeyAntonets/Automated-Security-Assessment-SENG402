{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f688550d",
   "metadata": {},
   "source": [
    "# Predicing pre- and postconditions using LLM #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af50b0",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2783da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from runningLLAMA import llama_local_generate\n",
    "from runningBaronLLM import baron_local_generate\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda94d8f",
   "metadata": {},
   "source": [
    "## Prepare the prompts ##\n",
    "Multiple prompts for ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cadc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1: Both vulnerability description AND CVSS vector\n",
    "prompt_both = \"\"\"\n",
    "    Classify the vulnerability post-condition privilege as one of the following:\n",
    "    - None: Attacker does not gain access to the system.  - User: Attacker gains\n",
    "    user-level access (e.g., running code as a normal user, accessing user\n",
    "    files).  - Root: Attacker gains full system or administrative access (e.g.,\n",
    "    root privileges, complete control over the system or application).\n",
    "\n",
    "    \n",
    "    Vulnerability: {description}\n",
    "    CVSS Vector: {cvss}\n",
    "    \n",
    "    Examples: Example 1: Vulnerability: XSS vulnerability allows stealing user\n",
    "    session cookies.  CVSS Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N\n",
    "    Classification: User Justification: Attacker gains access to user session\n",
    "    data but not system control.\n",
    "\n",
    "    Example 2: Vulnerability: SQL injection allows database manipulation.  CVSS\n",
    "    Vector: CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H Classification: User\n",
    "    Justification: Attacker gains database access but not full system control.\n",
    "\n",
    "    Now classify the given vulnerability: Justification: [Your justification]\n",
    "    ##POSTCONDITION [Your classification: None, User, or Root]\n",
    "    \"\"\"\n",
    "\n",
    "# Prompt 2: Only vulnerability description\n",
    "prompt_desc_only = \"\"\"\n",
    "    Classify the vulnerability post-condition privilege as one of the following:\n",
    "    - None: Attacker does not gain access to the system.  - User: Attacker gains\n",
    "    user-level access (e.g., running code as a normal user, accessing user\n",
    "    files).  - Root: Attacker gains full system or administrative access (e.g.,\n",
    "    root privileges, complete control over the system or application).\n",
    "\n",
    "    \n",
    "    Vulnerability: {description}\n",
    "    \n",
    "    Examples: Example 1: Vulnerability: XSS vulnerability allows stealing user\n",
    "    session cookies.  \n",
    "    Classification: User Justification: Attacker gains access to user session\n",
    "    data but not system control.\n",
    "\n",
    "    Example 2: Vulnerability: SQL injection allows database manipulation.  \n",
    "    Classification: User Justification: Attacker gains database access but not full system control.\n",
    "\n",
    "    Now classify the given vulnerability: Justification: [Your justification]\n",
    "    ##POSTCONDITION [Your classification: None, User, or Root]\n",
    "    \"\"\"\n",
    "\n",
    "# Prompt 3: Only CVSS vector\n",
    "prompt_cvss_only = \"\"\"\n",
    "    Classify the vulnerability post-condition privilege as one of the following:\n",
    "    - None: Attacker does not gain access to the system.  - User: Attacker gains\n",
    "    user-level access (e.g., running code as a normal user, accessing user\n",
    "    files).  - Root: Attacker gains full system or administrative access (e.g.,\n",
    "    root privileges, complete control over the system or application).\n",
    "\n",
    "    \n",
    "    CVSS Vector: {cvss}\n",
    "    \n",
    "    Examples: Example 1: CVSS Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N\n",
    "    Classification: User Justification: Low impact on confidentiality and integrity suggests user-level access.\n",
    "\n",
    "    Example 2: CVSS Vector: CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H \n",
    "    Classification: User Justification: High impact but requires high privileges, suggesting user-level access.\n",
    "\n",
    "    Now classify the given vulnerability: Justification: [Your justification]\n",
    "    ##POSTCONDITION [Your classification: None, User, or Root]\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418e7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_both = \"\"\"\n",
    "    You are a cybersecurity vulnerability classification expert. Your task is to\n",
    "    determine the post-condition privilege level after successful exploitation.\n",
    "\n",
    "    POST-CONDITION PRIVILEGE LEVEL DEFINITIONS: - None: Attacker does not gain\n",
    "    access to the system. No execution privileges are obtained.  - User:\n",
    "    Attacker gains user-level access (e.g., running code as a normal user,\n",
    "    accessing user files, limited privileges).  - Root: Attacker gains full\n",
    "    system or administrative access (e.g., root privileges, complete control\n",
    "    over the system or application, administrator rights).\n",
    "\n",
    "    CLASSIFICATION INSTRUCTIONS: 1. Analyze both the CVE description and CVSS\n",
    "    vector 2. Provide a brief justification 3. End your\n",
    "    response with: ##POSTCONDITION [classification] 4. The classification must\n",
    "    be EXACTLY one of: None, User, Root\n",
    "    \"\"\"\n",
    "\n",
    "sys_prompt_desc_only = \"\"\"\n",
    "    You are a cybersecurity vulnerability classification expert. Your task is to\n",
    "    determine the post-condition privilege level after successful exploitation.\n",
    "\n",
    "    POST-CONDITION PRIVILEGE LEVEL DEFINITIONS: - None: Attacker does not gain\n",
    "    access to the system. No execution privileges are obtained.  - User:\n",
    "    Attacker gains user-level access (e.g., running code as a normal user,\n",
    "    accessing user files, limited privileges).  - Root: Attacker gains full\n",
    "    system or administrative access (e.g., root privileges, complete control\n",
    "    over the system or application, administrator rights).\n",
    "\n",
    "    CLASSIFICATION INSTRUCTIONS: 1. Analyze the CVE description 2. Provide a brief \n",
    "    justification 3. End your response with: ##POSTCONDITION [classification] \n",
    "    4. The classification must be EXACTLY one of: None, User, Root\n",
    "    \"\"\"\n",
    "\n",
    "sys_prompt_cvss_only = \"\"\"\n",
    "    You are a cybersecurity vulnerability classification expert. Your task is to\n",
    "    determine the post-condition privilege level after successful exploitation.\n",
    "\n",
    "    POST-CONDITION PRIVILEGE LEVEL DEFINITIONS: - None: Attacker does not gain\n",
    "    access to the system. No execution privileges are obtained.  - User:\n",
    "    Attacker gains user-level access (e.g., running code as a normal user,\n",
    "    accessing user files, limited privileges).  - Root: Attacker gains full\n",
    "    system or administrative access (e.g., root privileges, complete control\n",
    "    over the system or application, administrator rights).\n",
    "\n",
    "    CLASSIFICATION INSTRUCTIONS: 1. Analyze the CVSS vector 2. Provide a brief \n",
    "    justification 3. End your response with: ##POSTCONDITION [classification] \n",
    "    4. The classification must be EXACTLY one of: None, User, Root\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended params for BaronLLM\n",
    "temperature = 0.3\n",
    "top_p = 0.9     \n",
    "seed = 42\n",
    "# Small number of output tokens to speed\n",
    "max_tokens = 256   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73636c19",
   "metadata": {},
   "source": [
    "## Format output ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f860d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_post_condition(text):\n",
    "    \"\"\"\n",
    "    Extract post-condition privilege classification from LLM response text.\n",
    "    Returns the last valid classification found and whether extraction was successful.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern for matching privilege classification\n",
    "    privilege_pattern = r'^(None|User|Root)[.:\\s]*$'\n",
    "    \n",
    "    # Split the text into lines (from bottom up) and search for a matching line\n",
    "    lines = text.strip().splitlines()\n",
    "    for line in reversed(lines):\n",
    "        line = line.strip()\n",
    "        if re.match(privilege_pattern, line):\n",
    "            # Extract just the classification word\n",
    "            match = re.match(r'^(None|User|Root)', line)\n",
    "            if match:\n",
    "                return match.group(1), True\n",
    "    \n",
    "    # If no exact match found, look for the classification word anywhere in the text\n",
    "    text_reversed = text[::-1]\n",
    "    for word in [\"tooR\", \"resU\", \"enoN\"]:  # Reversed words\n",
    "        if word in text_reversed:\n",
    "            pos = text_reversed.find(word)\n",
    "            return word[::-1], True  # Reverse back to original\n",
    "    \n",
    "    # If still not found, return the entire text and mark as failed\n",
    "    return text, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff188b",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad34da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_file_path = \"../datasets/postcondition-dataset-finished.tsv\"\n",
    "# run_evaluation(data_set_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e5997",
   "metadata": {},
   "source": [
    "### Ablation Study ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c249ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running ablation study with prompt: both ===\n"
     ]
    }
   ],
   "source": [
    "def run_ablation_study(file_path):\n",
    "    \"\"\"\n",
    "    Run ablation study with three different prompt variations:\n",
    "    1. Both vulnerability description AND CVSS vector\n",
    "    2. Only vulnerability description  \n",
    "    3. Only CVSS vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the three prompt variations with their corresponding system prompts\n",
    "    prompts = {\n",
    "        \"both\": (sys_prompt_both, prompt_both),\n",
    "        \"desc_only\": (sys_prompt_desc_only, prompt_desc_only), \n",
    "        \"cvss_only\": (sys_prompt_cvss_only, prompt_cvss_only)\n",
    "    }\n",
    "    \n",
    "    for prompt_name, (system_prompt, prompt_template) in prompts.items():\n",
    "        print(f\"\\n=== Running ablation study with prompt: {prompt_name} ===\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        count_chars = 0\n",
    "        instructions_failed = 0\n",
    "        \n",
    "        data = pd.read_csv(file_path, encoding='utf-8', sep='\\t')\n",
    "        all_results = []\n",
    "        all_full_responses = []\n",
    "        \n",
    "        for index, row in data.iterrows():\n",
    "            # Format the prompt based on the current variation\n",
    "            if prompt_name == \"both\":\n",
    "                llm_prompt = prompt_template.format(description=row['DESCRIPTION'], cvss=row['CVSS'])\n",
    "            elif prompt_name == \"desc_only\":\n",
    "                llm_prompt = prompt_template.format(description=row['DESCRIPTION'])\n",
    "            elif prompt_name == \"cvss_only\":\n",
    "                llm_prompt = prompt_template.format(cvss=row['CVSS'])\n",
    "            \n",
    "            try:\n",
    "                # Get prediction from the model using the specific system prompt for this variation\n",
    "                output = baron_local_generate(system_prompt, llm_prompt, max_tokens=max_tokens, temperature=temperature, top_p=top_p, seed=seed)\n",
    "                count_chars += len(output)\n",
    "                \n",
    "                # Store the full response\n",
    "                all_full_responses.append(f\"=== CVE {index+1} ===\\n{output}\\n\")\n",
    "                \n",
    "                # Try to extract post-condition from the response\n",
    "                answer, success = format_post_condition(output)\n",
    "                if not success:\n",
    "                    instructions_failed += 1\n",
    "                \n",
    "                all_results.append(answer)\n",
    "                print(f\"{index+1} {answer}\")\n",
    "            except Exception as e:\n",
    "                answer = 'Error'\n",
    "                error_msg = f\"=== CVE {index+1} ===\\nERROR: {str(e)}\\n\"\n",
    "                all_full_responses.append(error_msg)\n",
    "                all_results.append(answer)\n",
    "                print(f'Exception at row {index+1}')\n",
    "                print(e)\n",
    "        \n",
    "        time_taken = time.time() - start_time\n",
    "        print(f'Time taken for {prompt_name}: {time_taken}')\n",
    "        print(f'#Characters generated: {count_chars}')\n",
    "        print(f'#Instructions failed: {instructions_failed}')\n",
    "        \n",
    "        # Create output directory for ablation study\n",
    "        output_dir = os.path.join('responses', 'ablation-study')\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # Save results with prompt variation in filename\n",
    "        base_filename = os.path.basename(file_path).split('.')[0]\n",
    "        out_result = os.path.join(output_dir, f'SENG402_{base_filename}_postcondition_{prompt_name}.txt')\n",
    "        with open(out_result, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(all_results))\n",
    "        \n",
    "        out_full_responses = os.path.join(output_dir, f'SENG402_{base_filename}_full_postcondition_responses_{prompt_name}.txt')\n",
    "        with open(out_full_responses, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(all_full_responses))\n",
    "        \n",
    "        print(f'Results saved to: {out_result}')\n",
    "        print(f'Full responses saved to: {out_full_responses}')\n",
    "        print(f'------- {prompt_name} Done --------\\n')\n",
    "\n",
    "# Run the ablation study\n",
    "data_set_file_path = \"../datasets/postcondition-dataset-finished.tsv\"\n",
    "run_ablation_study(data_set_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0a7af",
   "metadata": {},
   "source": [
    "## Helper functions for evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb388c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_predictions(true_labels_file, pred_labels_file, prompt_name):\n",
    "    \"\"\"\n",
    "    Calculate F1 score and accuracy for predictions.\n",
    "    \n",
    "    Args:\n",
    "        true_labels_file: Path to file with ground truth labels (one per line)\n",
    "        pred_labels_file: Path to file with predicted labels (one per line)\n",
    "        prompt_name: Name of the prompt variant for reporting\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with F1 and accuracy scores\n",
    "    \"\"\"\n",
    "    # Read true labels and predicted labels\n",
    "    with open(true_labels_file, 'r', encoding='utf-8') as f:\n",
    "        true_labels = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    with open(pred_labels_file, 'r', encoding='utf-8') as f:\n",
    "        pred_labels = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # Ensure same length\n",
    "    min_len = min(len(true_labels), len(pred_labels))\n",
    "    true_labels = true_labels[:min_len]\n",
    "    pred_labels = pred_labels[:min_len]\n",
    "    \n",
    "    # Handle any prediction errors (replace with most common class or 'User')\n",
    "    valid_classes = ['None', 'User', 'Root']\n",
    "    pred_labels_clean = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    for pred in pred_labels:\n",
    "        if pred in valid_classes:\n",
    "            pred_labels_clean.append(pred)\n",
    "        else:\n",
    "            pred_labels_clean.append('User')  # Default fallback\n",
    "            failed_count += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels_clean)\n",
    "    f1_macro = f1_score(true_labels, pred_labels_clean, average='macro')  # Treats all classes equally\n",
    "    f1_weighted = f1_score(true_labels, pred_labels_clean, average='weighted')  # Weighted by class frequency\n",
    "    \n",
    "    return {\n",
    "        'prompt_name': prompt_name,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'failed_extractions': failed_count,\n",
    "        'total_predictions': len(pred_labels)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ABLATION STUDY vs GROUND TRUTH COMPARISON ===\n",
      "\n",
      "Variant\t\tAccuracy\tF1-Macro\tFailed Extractions\n",
      "-------------------------------------------------------\n",
      "both        \t0.727\t\t0.719\t\t0/33\n",
      "desc_only   \t0.576\t\t0.534\t\t0/33\n",
      "cvss_only   \t0.303\t\t0.252\t\t0/33\n",
      "\n",
      "=== BEST PERFORMANCE ===\n",
      "Best Accuracy: both (0.727)\n",
      "Best F1-Macro: both (0.719)\n",
      "\n",
      "=== DETAILED ANALYSIS FOR BEST VARIANT (both) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       1.00      0.45      0.62        11\n",
      "        User       0.90      0.75      0.82        12\n",
      "        Root       0.56      1.00      0.71        10\n",
      "\n",
      "    accuracy                           0.73        33\n",
      "   macro avg       0.82      0.73      0.72        33\n",
      "weighted avg       0.83      0.73      0.72        33\n",
      "\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "Row 1: ✗ True: Root | Pred: User\n",
      "Row 2: ✓ True: Root | Pred: Root\n",
      "Row 3: ✗ True: None | Pred: User\n",
      "Row 4: ✓ True: None | Pred: None\n",
      "Row 5: ✗ True: None | Pred: Root\n",
      "Row 6: ✓ True: User | Pred: User\n",
      "Row 7: ✓ True: None | Pred: None\n",
      "Row 8: ✗ True: None | Pred: User\n",
      "Row 9: ✓ True: User | Pred: User\n",
      "Row 10: ✓ True: Root | Pred: Root\n"
     ]
    }
   ],
   "source": [
    "def compare_ablation_with_ground_truth(dataset_file=\"../../datasets/postcondition-dataset-finished.tsv\", \n",
    "                                     results_dir='../responses/ablation-study'):\n",
    "    \"\"\"\n",
    "    Compare all three ablation study results with ground truth from the dataset.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "    \n",
    "    # Read ground truth from dataset\n",
    "    dataset = pd.read_csv(dataset_file, sep='\\t', encoding='utf-8', keep_default_na=False, na_values=[''])\n",
    "    ground_truth = dataset['POSTCONDITION'].str.strip().tolist()\n",
    "    \n",
    "    prompt_variants = ['both', 'desc_only', 'cvss_only']\n",
    "    results_summary = []\n",
    "    \n",
    "    print(\"=== ABLATION STUDY vs GROUND TRUTH COMPARISON ===\\n\")\n",
    "    print(\"Variant\\t\\tAccuracy\\tF1-Macro\\tFailed Extractions\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_f1_macro = 0\n",
    "    best_variant_acc = \"\"\n",
    "    best_variant_f1_macro = \"\"\n",
    "    \n",
    "    for variant in prompt_variants:\n",
    "        pred_file = os.path.join(results_dir, f'SENG402_postcondition-dataset-finished_postcondition_{variant}.txt')\n",
    "        \n",
    "        if os.path.exists(pred_file):\n",
    "            # Read predictions\n",
    "            with open(pred_file, 'r', encoding='utf-8') as f:\n",
    "                predictions = [line.strip() for line in f.readlines()]\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(ground_truth), len(predictions))\n",
    "            gt_subset = ground_truth[:min_len]\n",
    "            pred_subset = predictions[:min_len]\n",
    "            \n",
    "            # Handle failed extractions (replace invalid predictions with most common class)\n",
    "            valid_classes = ['None', 'User', 'Root']\n",
    "            pred_clean = []\n",
    "            failed_count = 0\n",
    "            \n",
    "            for pred in pred_subset:\n",
    "                if pred in valid_classes:\n",
    "                    pred_clean.append(pred)\n",
    "                else:\n",
    "                    pred_clean.append('User')  # Default fallback\n",
    "                    failed_count += 1\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(gt_subset, pred_clean)\n",
    "            f1_macro = f1_score(gt_subset, pred_clean, average='macro')\n",
    "            \n",
    "            # Store results\n",
    "            results_summary.append({\n",
    "                'variant': variant,\n",
    "                'accuracy': accuracy,\n",
    "                'f1_macro': f1_macro,\n",
    "                'failed_extractions': failed_count,\n",
    "                'total_predictions': len(pred_subset)\n",
    "            })\n",
    "            \n",
    "            print(f\"{variant:12}\\t{accuracy:.3f}\\t\\t{f1_macro:.3f}\\t\\t{failed_count}/{len(pred_subset)}\")\n",
    "            \n",
    "            # Track best performance\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_variant_acc = variant\n",
    "            if f1_macro > best_f1_macro:\n",
    "                best_f1_macro = f1_macro\n",
    "                best_variant_f1_macro = variant\n",
    "                \n",
    "        else:\n",
    "            print(f\"{variant:12}\\tFile not found\")\n",
    "    \n",
    "    print(\"\\n=== BEST PERFORMANCE ===\")\n",
    "    print(f\"Best Accuracy: {best_variant_acc} ({best_accuracy:.3f})\")\n",
    "    print(f\"Best F1-Macro: {best_variant_f1_macro} ({best_f1_macro:.3f})\")\n",
    "    \n",
    "    # Detailed per-class analysis for best performing variant\n",
    "    print(f\"\\n=== DETAILED ANALYSIS FOR BEST VARIANT ({best_variant_f1_macro}) ===\")\n",
    "    best_pred_file = os.path.join(results_dir, f'SENG402_postcondition-dataset-finished_postcondition_{best_variant_f1_macro}.txt')\n",
    "    \n",
    "    if os.path.exists(best_pred_file):\n",
    "        with open(best_pred_file, 'r', encoding='utf-8') as f:\n",
    "            best_predictions = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        min_len = min(len(ground_truth), len(best_predictions))\n",
    "        gt_subset = ground_truth[:min_len]\n",
    "        pred_subset = best_predictions[:min_len]\n",
    "        \n",
    "        # Clean predictions\n",
    "        pred_clean = [pred if pred in valid_classes else 'User' for pred in pred_subset]\n",
    "        \n",
    "        print(classification_report(gt_subset, pred_clean, target_names=['None', 'User', 'Root']))\n",
    "        \n",
    "        # Show some examples of correct and incorrect predictions\n",
    "        print(\"\\n=== SAMPLE PREDICTIONS ===\")\n",
    "        for i, (true_label, pred_label) in enumerate(zip(gt_subset, pred_clean)):\n",
    "            status = \"✓\" if true_label == pred_label else \"✗\"\n",
    "            print(f\"Row {i+1}: {status} True: {true_label:4} | Pred: {pred_label:4}\")\n",
    "            if i >= 9:  # Show first 10 examples\n",
    "                break\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Run the comparison\n",
    "results = compare_ablation_with_ground_truth()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
