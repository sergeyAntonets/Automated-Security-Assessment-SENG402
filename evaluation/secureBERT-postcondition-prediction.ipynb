{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a56101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693d0e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n",
      "Number of labels: 3\n",
      "Label mappings: {0: 'None', 1: 'User', 2: 'Root'}\n"
     ]
    }
   ],
   "source": [
    "# Define your label mappings\n",
    "id2label = {0: \"None\", 1: \"User\", 2: \"Root\"}\n",
    "label2id = {\"None\": 0, \"User\": 1, \"Root\": 2}\n",
    "\n",
    "# Load SecureBERT using AutoModelForSequenceClassification\n",
    "model_name = \"ehsanaghaei/SecureBERT\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,  # None, User, Root\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"Model architecture: {type(model)}\")\n",
    "print(f\"Number of labels: {model.num_labels}\")\n",
    "print(f\"Label mappings: {model.config.id2label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce72ff2",
   "metadata": {},
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7c5f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example from dataset_dict (before label conversion) ---\n",
      "Text: Description: A local privilege escalation vulnerability in the Intercept X for Windows installer prior version 1.22 can lead to a local user gaining system level privileges, if the installer is run as SYSTEM. CVSS: CVSS:3.1/AV:L/AC:H/PR:L/UI:R/S:C/C:H/I:H/A:H\n",
      "Label: Root\n",
      "\n",
      "Text: Description: Notepad++ is a free and open-source source code editor. In versions 8.8.1 and prior, a privilege escalation vulnerability exists in the Notepad++ v8.8.1 installer that allows unprivileged users to gain SYSTEM-level privileges through insecure executable search paths. An attacker could use social engineering or clickjacking to trick users into downloading both the legitimate installer and a malicious executable to the same directory (typically Downloads folder - which is known as Vulnerable directory). Upon running the installer, the attack executes automatically with SYSTEM privileges. This issue has been fixed and will be released in version 8.8.2. CVSS: CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n",
      "Label: Root\n",
      "\n",
      "Text: Description: Katran could disclose non-initialized kernel memory as part of an IP header. The issue was present for IPv4 encapsulation and ICMP (v4) Too Big packet generation. After a bpf_xdp_adjust_head call, Katran code didt initialize the Identification field for the IPv4 header, resulting in writing content of kernel memory in that field of IP header. The issue affected all Katran versions prior to commit 6a03106ac1eab39d0303662963589ecb2374c97f CVSS: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N\n",
      "Label: None\n",
      "\n",
      "Dataset size: 31\n",
      "Label distribution:\n",
      "Root    12\n",
      "User    10\n",
      "None     9\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceee16574da49ca8e7da5bad0412524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example from dataset (after label conversion) ---\n",
      "The string labels should now be integer IDs.\n",
      "{'text': 'Description: A local privilege escalation vulnerability in the Intercept X for Windows installer prior version 1.22 can lead to a local user gaining system level privileges, if the installer is run as SYSTEM. CVSS: CVSS:3.1/AV:L/AC:H/PR:L/UI:R/S:C/C:H/I:H/A:H', 'label': 2}\n",
      "{'text': 'Description: Notepad++ is a free and open-source source code editor. In versions 8.8.1 and prior, a privilege escalation vulnerability exists in the Notepad++ v8.8.1 installer that allows unprivileged users to gain SYSTEM-level privileges through insecure executable search paths. An attacker could use social engineering or clickjacking to trick users into downloading both the legitimate installer and a malicious executable to the same directory (typically Downloads folder - which is known as Vulnerable directory). Upon running the installer, the attack executes automatically with SYSTEM privileges. This issue has been fixed and will be released in version 8.8.2. CVSS: CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H', 'label': 2}\n",
      "{'text': 'Description: Katran could disclose non-initialized kernel memory as part of an IP header. The issue was present for IPv4 encapsulation and ICMP (v4) Too Big packet generation. After a bpf_xdp_adjust_head call, Katran code didt initialize the Identification field for the IPv4 header, resulting in writing content of kernel memory in that field of IP header. The issue affected all Katran versions prior to commit 6a03106ac1eab39d0303662963589ecb2374c97f CVSS: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N', 'label': 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d76e44736b43ef829aaf5c6705157a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 24\n",
      "Evaluation samples: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91486/438418656.py:125: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.104492</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>1.104771</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>1.104911</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.104632</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.103100</td>\n",
       "      <td>1.104632</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.103100</td>\n",
       "      <td>1.104911</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.102600</td>\n",
       "      <td>1.105050</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.102600</td>\n",
       "      <td>1.104911</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.100900</td>\n",
       "      <td>1.105050</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.096000</td>\n",
       "      <td>1.105190</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model...\n",
      "Model saved to ./securebert-privilege-classifier-final\n",
      "Evaluating final model...\n",
      "Model saved to ./securebert-privilege-classifier-final\n",
      "Evaluating final model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation metrics: {'eval_loss': 1.1044921875, 'eval_accuracy': 0.14285714285714285, 'eval_runtime': 0.0471, 'eval_samples_per_second': 148.527, 'eval_steps_per_second': 42.436, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# 1. Load model and tokenizer\n",
    "model_name = \"ehsanaghaei/SecureBERT\"\n",
    "id2label = {0: \"None\", 1: \"User\", 2: \"Root\"}\n",
    "label2id = {\"None\": 0, \"User\": 1, \"Root\": 2}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "# Apply PEFT (LoRA)\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,                    # Low rank for small dataset\n",
    "    lora_alpha=32,          # Scaling factor\n",
    "    lora_dropout=0.2,       # Higher dropout for regularization\n",
    "    target_modules=[\"query\", \"value\", \"key\"],  # Target attention layers\n",
    "    bias=\"none\"             # Don't train bias terms\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 2. Load the actual dataset\n",
    "df = pd.read_csv(\"../datasets/postcondition-dataset-finished.tsv\", sep='\\t')\n",
    "\n",
    "# Clean the data and prepare for training\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.dropna(subset=['DESCRIPTION', 'CVSS', 'POSTCONDITION'])  # Remove rows with missing values in essential columns\n",
    "df['POSTCONDITION'] = df['POSTCONDITION'].str.strip()  # Remove whitespace\n",
    "\n",
    "# Combine description and CVSS into text format\n",
    "df['text'] = \"Description: \" + df['DESCRIPTION'] + \" CVSS: \" + df['CVSS']\n",
    "\n",
    "# Prepare dataset in the format needed for training\n",
    "dataset_dict = {\n",
    "    \"text\": df['text'].tolist(),\n",
    "    \"label\": df['POSTCONDITION'].tolist()\n",
    "}\n",
    "\n",
    "print(\"--- Example from dataset_dict (before label conversion) ---\")\n",
    "for i in range(3): # Print the first 3 samples\n",
    "    print(f\"Text: {dataset_dict['text'][i]}\")\n",
    "    print(f\"Label: {dataset_dict['label'][i]}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Dataset size: {len(dataset_dict['text'])}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(pd.Series(dataset_dict['label']).value_counts())\n",
    "\n",
    "# Convert to dataset\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "# Convert labels to numeric\n",
    "def format_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(format_labels)\n",
    "\n",
    "print(\"\\n--- Example from dataset (after label conversion) ---\")\n",
    "print(\"The string labels should now be integer IDs.\")\n",
    "print(dataset[0])\n",
    "print(dataset[1])\n",
    "print(dataset[2])\n",
    "\n",
    "\n",
    "# 3. Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 4. Split dataset (80% train, 20% test) with consistent seed\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")\n",
    "\n",
    "# 5. Setup evaluation\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 6. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./securebert-privilege-classifier\",\n",
    "    learning_rate=1e-5,  # Lower learning rate\n",
    "    per_device_train_batch_size=4,  # Smaller batch size\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,  # More epochs with early stopping\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients\n",
    "    warmup_steps=10,  # Add warmup\n",
    "    fp16=True,  # Use mixed precision if GPU available\n",
    ")\n",
    "\n",
    "# 7. Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 8. Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save the trained model and tokenizer\n",
    "print(\"Saving trained model...\")\n",
    "trainer.save_model(\"./securebert-privilege-classifier-final\")\n",
    "tokenizer.save_pretrained(\"./securebert-privilege-classifier-final\")\n",
    "print(\"Model saved to ./securebert-privilege-classifier-final\")\n",
    "\n",
    "# 10. Get final evaluation metrics\n",
    "print(\"Evaluating final model...\")\n",
    "final_metrics = trainer.evaluate()\n",
    "print(f\"Final evaluation metrics: {final_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6e113",
   "metadata": {},
   "source": [
    "## Model Testing and Results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def test_on_held_out_set(model, tokenizer, test_dataset, output_file=\"securebert_test_results.csv\"):\n",
    "    \"\"\"Test the trained model on the held-out test set and save results\"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Testing model on {len(test_dataset)} samples...\")\n",
    "    \n",
    "    for i, sample in enumerate(test_dataset):\n",
    "        # Reconstruct the original text\n",
    "        text = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "        \n",
    "        # Get prediction\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "            confidence = predictions[0][predicted_class].item()\n",
    "        \n",
    "        # Convert labels back to text\n",
    "        true_label = model.config.id2label[sample['label']]\n",
    "        predicted_label = model.config.id2label[predicted_class]\n",
    "        \n",
    "        # Get all probabilities\n",
    "        all_probs = {\n",
    "            model.config.id2label[i]: predictions[0][i].item() \n",
    "            for i in range(len(model.config.id2label))\n",
    "        }\n",
    "        \n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'confidence': confidence,\n",
    "            'correct': true_label == predicted_label,\n",
    "            'prob_none': all_probs['None'],\n",
    "            'prob_user': all_probs['User'],\n",
    "            'prob_root': all_probs['Root']\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(test_dataset)} test samples\")\n",
    "    \n",
    "    # Save results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = df_results['correct'].mean()\n",
    "    total_samples = len(df_results)\n",
    "    correct_predictions = df_results['correct'].sum()\n",
    "    \n",
    "    print(f\"\\n=== TEST SET RESULTS ===\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class breakdown\n",
    "    print(f\"\\n=== PER-CLASS RESULTS ===\")\n",
    "    for label in ['None', 'User', 'Root']:\n",
    "        subset = df_results[df_results['true_label'] == label]\n",
    "        if len(subset) > 0:\n",
    "            class_accuracy = subset['correct'].mean()\n",
    "            print(f\"{label}: {len(subset)} samples, {class_accuracy:.4f} accuracy ({class_accuracy*100:.1f}%)\")\n",
    "            \n",
    "            # Show what this class was predicted as\n",
    "            pred_counts = subset['predicted_label'].value_counts()\n",
    "            for pred_label, count in pred_counts.items():\n",
    "                percentage = (count / len(subset)) * 100\n",
    "                print(f\"  -> Predicted as {pred_label}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    print(f\"\\n=== CONFIDENCE ANALYSIS ===\")\n",
    "    high_conf = df_results[df_results['confidence'] >= 0.9]\n",
    "    med_conf = df_results[(df_results['confidence'] >= 0.7) & (df_results['confidence'] < 0.9)]\n",
    "    low_conf = df_results[df_results['confidence'] < 0.7]\n",
    "    \n",
    "    print(f\"High confidence (≥90%): {len(high_conf)} samples, {high_conf['correct'].mean():.4f} accuracy\")\n",
    "    print(f\"Medium confidence (70-90%): {len(med_conf)} samples, {med_conf['correct'].mean():.4f} accuracy\")\n",
    "    print(f\"Low confidence (<70%): {len(low_conf)} samples, {low_conf['correct'].mean():.4f} accuracy\")\n",
    "    \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Test the model on the held-out test set\n",
    "print(\"Testing trained model on held-out test set...\")\n",
    "test_results = test_on_held_out_set(model, tokenizer, eval_dataset, \"securebert_test_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba7737",
   "metadata": {},
   "source": [
    "## Inference ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_privilege(description, cvss_vector, model, tokenizer):\n",
    "    \"\"\"Predict privilege level using the fine-tuned model\"\"\"\n",
    "    # Prepare input\n",
    "    text = f\"Description: {description} CVSS: {cvss_vector}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Move to device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "    \n",
    "    return {\n",
    "        \"predicted_privilege\": model.config.id2label[predicted_class],\n",
    "        \"confidence\": confidence,\n",
    "        \"all_probabilities\": {\n",
    "            model.config.id2label[i]: predictions[0][i].item() \n",
    "            for i in range(len(model.config.id2label))\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "description = \"Buffer overflow allowing arbitrary code execution\"\n",
    "cvss_vector = \"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\"\n",
    "\n",
    "result = predict_privilege(description, cvss_vector, model, tokenizer)\n",
    "print(f\"Predicted privilege: {result['predicted_privilege']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"All probabilities: {result['all_probabilities']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
