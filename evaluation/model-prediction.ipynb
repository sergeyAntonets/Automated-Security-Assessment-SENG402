{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b6af60-f174-4dc7-a6b8-2ad51d8af784",
   "metadata": {},
   "source": [
    "# Notebook to run GPT, Gemini, LLAMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76192d8",
   "metadata": {},
   "source": [
    "### Install All Required Packages\n",
    "Run this cell first to install all necessary packages if not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ebccfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install openai replicate python-dotenv pandas numpy matplotlib google.genai transformers torch bitsandbytes llamaapi accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9372cb3",
   "metadata": {},
   "source": [
    "# Notebook to run GPT, Gemini, LLAMA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b88102b-a07f-4763-9fcb-a2bd248d00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from llamaapi import LlamaAPI\n",
    "\n",
    "# from runningLLAMA import llama_local_generate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd791ee-3c67-4eb6-8678-827dfbf3bbb7",
   "metadata": {},
   "source": [
    "## Setup all APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3d6a19-2b3a-4918-8c69-98313903ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10403f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llama api\n",
    "llama_client = OpenAI(\n",
    "api_key = os.getenv(\"LLAMA_API_KEY\"),\n",
    "base_url = \"https://api.llmapi.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9787e703-fd56-4d6f-82d1-e00ef4137503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPEN_AI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff0eb4ea-6fea-407a-8de1-7f2ed22b8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini\n",
    "gemini_client = genai.Client(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0f299-880a-45d6-88a4-7b33448a7fb3",
   "metadata": {},
   "source": [
    "## LLM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5141f2a9-a4d2-4d57-b043-9873d213dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for deterministic and consistent model outputs across different LLMs\n",
    "# Low temperature and top_p reduce randomness, seed ensures reproducibility\n",
    "temperature = 0\n",
    "top_p = 0\n",
    "seed = 42\n",
    "max_tokens = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6e074a-85de-48c7-982e-339dbce560af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = 'You are a cybersecurity expert specializing in cyberthreat intelligence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcb01b07-3377-4845-a5a9-74719a86ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map internal model identifiers to actual API model names\n",
    "model_mapping = {\n",
    "    'api-llama3.1': 'llama3.1-8b',\n",
    "    'api-llama3.3': 'llama3.3-70b',\n",
    "    'gemini': 'gemini-2.0-flash', \n",
    "    'gpt-4o-mini': 'gpt-4o-mini',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4890ce6-7c73-4512-9316-64d49cc20607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_prediction(question, model_name):\n",
    "    \"\"\"\n",
    "    Get a single prediction from various LLM providers based on model name.\n",
    "    Handles OpenAI GPT, Google Gemini, local LLAMA, and API-based LLAMA models.\n",
    "    \"\"\"\n",
    "    if model_name.startswith('gpt'):\n",
    "        # ChatGPT API call with parameters\n",
    "        model = model_mapping[model_name]\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': sys_prompt},\n",
    "                {'role': 'user', 'content': question}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_tokens,\n",
    "            seed=seed\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "    elif model_name.startswith('gemini'):\n",
    "        # Gemini API with safety settings and retry logic for rate limiting\n",
    "        model = model_mapping[model_name]\n",
    "\n",
    "        # Create message content combining system prompt and user question\n",
    "        contents = [\n",
    "            types.Content(role=\"user\", parts=[types.Part(text=sys_prompt + \" \" + question)])\n",
    "        ]        \n",
    "        \n",
    "        # Configure safety settings to allow more content through\n",
    "        safety_settings = [\n",
    "            types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH),\n",
    "            types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH),\n",
    "            types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH),\n",
    "            types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH),\n",
    "        ]\n",
    "       \n",
    "        generation_config = types.GenerateContentConfig(\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_output_tokens=max_tokens,\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "       \n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generation_config,\n",
    "        )\n",
    "\n",
    "        # Retry logic to handle rate limiting (429 errors)\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                response = gemini_client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=contents,\n",
    "                    config=generation_config,\n",
    "                )\n",
    "                output = response.candidates[0].content.parts[0].text\n",
    "                time.sleep(1)  # Regular delay between requests\n",
    "                break\n",
    "            except Exception as e:\n",
    "                error_str = str(e)\n",
    "                if \"429 RESOURCE_EXHAUSTED\" in error_str:\n",
    "                    retry_count += 1\n",
    "                    print(f\"Rate limit hit, retrying in 2 seconds... (attempt {retry_count}/{max_retries})\")\n",
    "                    time.sleep(2)  # Wait for 2 seconds as suggested by API\n",
    "                    if retry_count == max_retries:\n",
    "                        output = f\"Error: Rate limit exceeded after {max_retries} attempts.\"\n",
    "                else:\n",
    "                    output = f\"Error: {str(e)}\"\n",
    "                    break\n",
    "                \n",
    "    elif model_name.startswith('llama-local'):\n",
    "        # Local LLAMA model - temperature must be > 0 to avoid errors\n",
    "        output = llama_local_generate(sys_prompt, question, max_tokens=max_tokens, temperature=0.01, top_p=top_p, seed=seed)\n",
    "\n",
    "    elif model_name.startswith('api-llama'):\n",
    "         # API-based LLAMA models through LLMapi service\n",
    "         model = model_mapping[model_name]\n",
    "         response = llama_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': sys_prompt},\n",
    "                {'role': 'user', 'content': question}\n",
    "            ],\n",
    "            temperature=0.01,  # Slightly above 0 for LLAMA models\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_tokens,\n",
    "            seed=seed\n",
    "        )\n",
    "         output = response.choices[0].message.content\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Model '{model_name}' not supported or not found in model_mapping\")\n",
    "        \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb481fe-ff69-42af-8306-4eb4f5d48973",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cd8376-21b9-4c91-b86d-876f1da04260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt to see if the API calls are working correctly\n",
    "question = (\n",
    "    \"Analyze the following CVE description and calculate the CVSS v3.1 Base Score. \"\n",
    "    \"Determine the values for each base metric: AV, AC, PR, UI, S, C, I, and A. \"\n",
    "    \"Summarize each metric's value and provide the final CVSS v3.1 vector string.   \"\n",
    "    \"Valid options for each metric are as follows: \\n\"\n",
    "    \"- **Attack Vector (AV)**: Network (N), Adjacent (A), Local (L), Physical (P)\\n\"\n",
    "    \"- **Attack Complexity (AC)**: Low (L), High (H)\\n\"\n",
    "    \"- **Privileges Required (PR)**: None (N), Low (L), High (H)\\n\"\n",
    "    \"- **User Interaction (UI)**: None (N), Required (R)\\n\"\n",
    "    \"- **Scope (S)**: Unchanged (U), Changed (C)\\n\"\n",
    "    \"- **Confidentiality (C)**: None (N), Low (L), High (H)\\n\"\n",
    "    \"- **Integrity (I)**: None (N), Low (L), High (H)\\n\"\n",
    "    \"- **Availability (A)**: None (N), Low (L), High (H)\\n\"\n",
    "    \"Summarize each metric's value and provide the final CVSS v3.1 vector string. \"\n",
    "    \"Ensure the final line of your response contains ONLY the CVSS v3 Vector String (no other text) \"\n",
    "    \"in the following format:  \\n\"\n",
    "    \"Example format: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\\n\\n\"\n",
    "    \"CVE Description: In the Linux kernel through 6.7.1, there is a use-after-free \"\n",
    "    \"in cec_queue_msg_fh, related to drivers/media/cec/core/cec-adap.c and \"\n",
    "    \"drivers/media/cec/core/cec-api.c.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c5ac66-c0a8-4a32-81b0-4c45d68092ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the CVE description and determine the CVSS v3.1 base score.\n",
      "\n",
      "*   **Attack Vector (AV):** Local (L). The vulnerability requires local access to the system to trigger the use-after-free.\n",
      "\n",
      "*   **Attack Complexity (AC):** Low (L). Triggering a use-after-free typically doesn't require complex conditions.\n",
      "\n",
      "*   **Privileges Required (PR):** Low (L). Exploiting a use-after-free often requires some level of privileges to interact with the affected driver.\n",
      "\n",
      "*   **User Interaction (UI):** None (N). The vulnerability can be triggered without any user interaction.\n",
      "\n",
      "*   **Scope (S):** Unchanged (U). The vulnerability affects the kernel, but the impact is likely limited to the kernel itself.\n",
      "\n",
      "*   **Confidentiality (C):** High (H). A use-after-free can potentially lead to information disclosure.\n",
      "\n",
      "*   **Integrity (I):** High (H). A use-after-free can potentially lead to arbitrary code execution and modification of system data.\n",
      "\n",
      "*   **Availability (A):** High (H). A use-after-free can potentially lead to a denial of service.\n",
      "\n",
      "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_single_prediction(question, 'gemini'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0c673-8d44-43b7-a04a-73f1ec36e2a9",
   "metadata": {},
   "source": [
    "# Run Evaluation on Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86580bd3-20e4-4952-af00-e49810c7703c",
   "metadata": {},
   "source": [
    "While this captures most output format of the LLMs, sometimes have to manually collect some responses from the generated response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "176c5b73-af68-443f-8b80-f1cfec5df3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(text):\n",
    "    \"\"\"\n",
    "    Extract CVSS v3.1 vector string from LLM response text.\n",
    "    Returns the last valid CVSS vector found and whether extraction was successful.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern for CVSS v3.1 vector string format\n",
    "    # Matches: AV:X/AC:X/PR:X/UI:X/S:X/C:X/I:X/A:X where X can be letters\n",
    "    cvss_pattern = r'AV:[A-Za-z]+/AC:[A-Za-z]+/PR:[A-Za-z]+/UI:[A-Za-z]+/S:[A-Za-z]+/C:[A-Za-z]+/I:[A-Za-z]+/A:[A-Za-z]+'\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(cvss_pattern, text)\n",
    "\n",
    "    # Return the last match (most likely to be the final answer) if any match is found\n",
    "    if matches:\n",
    "        return matches[-1], True\n",
    "    else:\n",
    "        # Return original text if no valid CVSS vector found (indicates parsing failure)\n",
    "        return text, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6068fb-49a8-4d80-b7d4-0d5f58750a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(file_path, model_name):\n",
    "    \"\"\"\n",
    "    Run CVSS prediction evaluation on a dataset using specified model.\n",
    "    Processes each CVE description, extracts CVSS vectors, and saves results.\n",
    "    \"\"\"\n",
    "    # Track performance metrics for the evaluation run\n",
    "    start_time = time.time()\n",
    "    count_chars = 0  # Total characters generated by the model\n",
    "    instructions_failed = 0  # Count of responses that didn't follow CVSS format\n",
    "    \n",
    "    # Load the dataset (TSV format with CVE descriptions and prompts)\n",
    "    data = pd.read_csv(file_path, encoding='utf-8', sep='\\t')\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each row in the dataset\n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row['Prompt']\n",
    "        try:\n",
    "            # Get prediction from the specified model\n",
    "            output = get_single_prediction(prompt, model_name)\n",
    "            count_chars += len(output)\n",
    "            \n",
    "            # Try to extract CVSS vector from the response\n",
    "            answer, success = format(output)\n",
    "            if not success:\n",
    "                instructions_failed += 1  # Model didn't follow CVSS format instructions\n",
    "            \n",
    "            all_results.append(answer)\n",
    "            print(index+1, answer)\n",
    "        except Exception as e:\n",
    "            # Handle any API errors or model failures\n",
    "            answer = 'Error'\n",
    "            all_results.append(answer)\n",
    "            print('Exception at row ', index+1)\n",
    "            print(e)\n",
    "            print(index+1, answer)\n",
    "\n",
    "    # Calculate and display performance metrics\n",
    "    time_taken = time.time() - start_time\n",
    "    print('Time taken:', time_taken)\n",
    "    print('#Characters generated:', count_chars)\n",
    "    print('#Instructions failed:', instructions_failed)\n",
    "\n",
    "    # Ensure output directory structure exists\n",
    "    output_dir = os.path.join('responses', 'individual-results')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save results to file with standardized naming convention\n",
    "    # Format: SENG402_<dataset-name>_<model-name>_result.txt\n",
    "    out_result = os.path.join(output_dir, 'SENG402_' + os.path.basename(file_path).split('.')[0] + '_' + model_name + '_result.txt')\n",
    "    with open(out_result, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(all_results))\n",
    "\n",
    "    print('------- Done --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3123f72-0838-4fc1-8ebe-912219909344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "2 AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:N\n",
      "3 AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N\n",
      "4 AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N\n",
      "5 AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H\n",
      "6 AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H\n",
      "Time taken: 40.646018505096436\n",
      "#Characters generated: 10827\n",
      "#Instructions failed: 0\n",
      "------- Done --------\n"
     ]
    }
   ],
   "source": [
    "run_evaluation('../datasets/2024-and-2025-SMALL.tsv', 'gemini')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
