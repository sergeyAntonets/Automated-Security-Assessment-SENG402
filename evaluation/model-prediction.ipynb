{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b6af60-f174-4dc7-a6b8-2ad51d8af784",
   "metadata": {},
   "source": [
    "# Notebook to run GPT, Gemini, Replicate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76192d8",
   "metadata": {},
   "source": [
    "## Install All Required Packages\n",
    "Run this cell first to install all necessary packages if not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ebccfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "#  %pip install openai replicate python-dotenv pandas numpy matplotli google.genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9372cb3",
   "metadata": {},
   "source": [
    "# Notebook to run GPT, Gemini, Replicate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b88102b-a07f-4763-9fcb-a2bd248d00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import replicate\n",
    "\"\"\" import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, HarmBlockThreshold, HarmCategory\n",
    " \"\"\"\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd791ee-3c67-4eb6-8678-827dfbf3bbb7",
   "metadata": {},
   "source": [
    "## Setup all APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d3d6a19-2b3a-4918-8c69-98313903ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replicate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9787e703-fd56-4d6f-82d1-e00ef4137503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPEN_AI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff0eb4ea-6fea-407a-8de1-7f2ed22b8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini\n",
    "# project_id = \"\"   # add project ID and location\n",
    "# vertexai.init(project=project_id, location=\"\")\n",
    "\n",
    "gemini_client = genai.Client(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0f299-880a-45d6-88a4-7b33448a7fb3",
   "metadata": {},
   "source": [
    "## Prediction Params & Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5141f2a9-a4d2-4d57-b043-9873d213dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for more deterministic output\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "seed = 42\n",
    "max_tokens = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b6e074a-85de-48c7-982e-339dbce560af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = 'You are a cybersecurity expert specializing in cyberthreat intelligence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcb01b07-3377-4845-a5a9-74719a86ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping = {\n",
    "    'llama3-70b': 'meta/meta-llama-3-70b-instruct',\n",
    "    'llama3-8b': 'meta/meta-llama-3-8b-instruct',\n",
    "    'gemini': 'gemini-2.5-pro-exp-03-25', \n",
    "    'gpt3': 'gpt-3.5-turbo',\n",
    "    'gpt4': 'gpt-4-turbo',\n",
    "    'gpt-4o-mini': 'gpt-4o-mini',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4890ce6-7c73-4512-9316-64d49cc20607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_prediction(question, model_name):\n",
    "    if model_name.startswith('llama') or model_name.startswith('mistral'):\n",
    "        # replicate\n",
    "        model = model_mapping[model_name]\n",
    "        prompt = sys_prompt + ' ' + question\n",
    "        input = {'prompt': prompt, 'max_tokens': max_tokens, 'temperature': temperature, 'top_p': top_p, 'seed': seed}\n",
    "        output = replicate.run(model, input=input)\n",
    "        output = \"\".join(output)\n",
    "    elif model_name.startswith('gemma'):\n",
    "        # replicate\n",
    "        model = model_mapping[model_name]\n",
    "        prompt = sys_prompt + ' ' + question\n",
    "        input = {'prompt': prompt, 'max_tokens': max_tokens, 'temperature': 0.01, 'top_p': top_p, 'seed': seed}\n",
    "        output = replicate.run(model, input=input)\n",
    "        output = \"\".join(output)\n",
    "    elif model_name.startswith('01-ai'):\n",
    "        # replicate\n",
    "        model = model_mapping[model_name]\n",
    "        prompt = sys_prompt + ' ' + question\n",
    "        input = {'prompt': prompt, 'max_tokens': max_tokens, 'temperature': temperature, 'top_p': top_p, 'seed': seed}\n",
    "        output = replicate.run(model, input=input)\n",
    "        output = \"\".join(output)\n",
    "    elif model_name.startswith('gpt'):\n",
    "        # ChatGPT\n",
    "        model = model_mapping[model_name]\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': sys_prompt},\n",
    "                {'role': 'user', 'content': question}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_tokens,\n",
    "            seed=seed\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "    elif model_name.startswith('gemini'):\n",
    "        # Gemini\n",
    "        model = model_mapping[model_name]\n",
    "        prompt = sys_prompt + ' ' + question\n",
    "        \n",
    "        # Use gemini_client instead of Vertex AI's GenerativeModel\n",
    "        safety_settings = {\n",
    "            types.HarmCategory.HARM_CATEGORY_HARASSMENT: types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        }\n",
    "        \n",
    "        generation_config = {\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"max_output_tokens\": max_tokens,\n",
    "        }\n",
    "        \n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=prompt,\n",
    "            config=generation_config,\n",
    "        )\n",
    "        \n",
    "        output = response.text\n",
    "        time.sleep(1)   # so it doesn't throw error\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb481fe-ff69-42af-8306-4eb4f5d48973",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26cd8376-21b9-4c91-b86d-876f1da04260",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = (\n",
    "    \"Analyze the following CVE description and map it to the appropriate CWE. \"\n",
    "    \"Provide a brief justification. The last line of your answer should only contain the CWE ID.\\n\\n\"\n",
    "    \"CVE Description:\\n\\n\"\n",
    "    \"Dell EMC CloudLink 7.1 and all prior versions contain an Improper Input Validation Vulnerability. \"\n",
    "    \"A remote low privileged attacker may potentially exploit this vulnerability, \"\n",
    "    \"leading to execution of arbitrary files on the server.\"\n",
    ")\n",
    "\n",
    "question2 = (\"Analyze the following CVE description and calculate the CVSS v3.1 Base Score. Determine the values for each base metric: AV, AC, PR, UI, S, C, I, and A. Summarize each metric's value and provide the final CVSS v3.1 vector string.   Valid options for each metric are as follows: - **Attack Vector (AV)**: Network (N), Adjacent (A), Local (L), Physical (P) - **Attack Complexity (AC)**: Low (L), High (H) - **Privileges Required (PR)**: None (N), Low (L), High (H) - **User Interaction (UI)**: None (N), Required (R) - **Scope (S)**: Unchanged (U), Changed (C) - **Confidentiality (C)**: None (N), Low (L), High (H) - **Integrity (I)**: None (N), Low (L), High (H) - **Availability (A)**: None (N), Low (L), High (H)  Summarize each metric's value and provide the final CVSS v3.1 vector string. Ensure the final line of your response contains only the CVSS v3 Vector String in the following format:  Example format: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H  CVE Description: The Orbit Fox by ThemeIsle plugin for WordPress is vulnerable to Stored Cross-Site Scripting via the plugin's Pricing Table Elementor Widget in all versions up to, and including, 2.10.27 due to insufficient input sanitization and output escaping on the user supplied link URL. This makes it possible for authenticated attackers with contributor-level and above permissions to inject arbitrary web scripts in pages that will execute whenever a user accesses an injected page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b473c-9b93-46f9-9ac5-6fb8e3fe314c",
   "metadata": {},
   "source": [
    "##### Are all the APIS working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6699f587-4e5c-4a59-a545-265fa4762fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_single_prediction(question, 'gpt-4o-mini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79c5ac66-c0a8-4a32-81b0-4c45d68092ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's analyze the CVE description and determine the CVSS v3.1 Base Score metrics.\n",
      "\n",
      "**CVE Description Analysis:**\n",
      "\n",
      "*   **Vulnerability:** Stored Cross-Site Scripting (XSS).\n",
      "*   **Component:** Orbit Fox plugin for WordPress, specifically the Pricing Table Elementor Widget.\n",
      "*   **Mechanism:** Insufficient input sanitization and output escaping on a link URL field.\n",
      "*   **Attacker Requirements:** Authenticated user with contributor-level (or higher) permissions.\n",
      "*   **Exploitation:** Attacker injects script via the vulnerable widget field. The script\n"
     ]
    }
   ],
   "source": [
    "print(get_single_prediction(question2, 'gemini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57c22fb5-bb3d-47f1-bbf2-da27188a0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_single_prediction(question, 'llama3-8b'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0c673-8d44-43b7-a04a-73f1ec36e2a9",
   "metadata": {},
   "source": [
    "# Run Evaluation for a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86580bd3-20e4-4952-af00-e49810c7703c",
   "metadata": {},
   "source": [
    "### All formatting comes here\n",
    "While these captures most output format of the LLMs we studied, we still had to manually collect some responses from the generated response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176c5b73-af68-443f-8b80-f1cfec5df3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rcm(text):\n",
    "    # Define the regex pattern for CWE ID\n",
    "    cwe_pattern = r'CWE-\\d+'\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(cwe_pattern, text)\n",
    "\n",
    "    # Return the last match if any match is found, otherwise return the original text\n",
    "    if matches:\n",
    "        return matches[-1], True\n",
    "    else:\n",
    "        return text, False\n",
    "\n",
    "def format_vsp(text):\n",
    "    # Define the regex pattern for CVSS v3.1 vector string\n",
    "    #cvss_pattern = r'AV:[^/]+?/AC:[^/]+?/PR:[^/]+?/UI:[^/]+?/S:[^/]+?/C:[^/]+?/I:[^/]+?/A:[^/]+?'\n",
    "    cvss_pattern = r'AV:[A-Za-z]+/AC:[A-Za-z]+/PR:[A-Za-z]+/UI:[A-Za-z]+/S:[A-Za-z]+/C:[A-Za-z]+/I:[A-Za-z]+/A:[A-Za-z]+'\n",
    "\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(cvss_pattern, text)\n",
    "\n",
    "    # Return the last match if any match is found, otherwise return the original text\n",
    "    if matches:\n",
    "        return matches[-1], True\n",
    "    else:\n",
    "        return text, False\n",
    "\n",
    "def format_mcq(text):\n",
    "    last_line = text.split('\\n')[-1].rstrip()\n",
    "    if last_line.startswith('A)') or last_line.startswith('B)') or last_line.startswith('C)') or last_line.startswith('D)'):\n",
    "        return last_line[0]\n",
    "    if last_line.endswith('A') or last_line.endswith('B') or last_line.endswith('C') or last_line.endswith('D'):\n",
    "        return last_line[-1]\n",
    "    if last_line.endswith('**'):\n",
    "        return last_line[-3]\n",
    "    if len(last_line) == 0:\n",
    "        last_line = text.split('\\n')[-2].rstrip()\n",
    "        if last_line.startswith('A)') or last_line.startswith('B)') or last_line.startswith('C)') or last_line.startswith('D)'):\n",
    "            return last_line[0]\n",
    "        if last_line.endswith('A') or last_line.endswith('B') or last_line.endswith('C') or last_line.endswith('D'):\n",
    "            return last_line[-1]\n",
    "        if last_line.endswith('**'):\n",
    "            return last_line[-3]\n",
    "    return ' '.join(text.split('\\n'))\n",
    "\n",
    "def format_taa(text):\n",
    "    # need to manually extract the attribution\n",
    "    return ' '.join(text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc6068fb-49a8-4d80-b7d4-0d5f58750a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(file_path, task, model_name):\n",
    "    # Keep track of time and total #chars generated\n",
    "    start_time = time.time()\n",
    "    count_chars = 0\n",
    "    instructions_failed = 0\n",
    "    \n",
    "    data = pd.read_csv(file_path, encoding='utf-8', sep='\\t')\n",
    "\n",
    "    # response contain the entire response, result the formatted result\n",
    "    all_responses = []\n",
    "    all_results = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row['Prompt']\n",
    "        try:\n",
    "            output = get_single_prediction(prompt, model_name)\n",
    "            \n",
    "            count_chars += len(output)\n",
    "            all_responses.append(output)\n",
    "            if task == 'rcm':\n",
    "                answer, success = format_rcm(output)\n",
    "                if not success:\n",
    "                    instructions_failed += 1\n",
    "            elif task == 'vsp':\n",
    "                answer, success = format_vsp(output)\n",
    "                if not success:\n",
    "                    instructions_failed += 1      \n",
    "            elif task == 'mcq':\n",
    "                answer = format_mcq(output)\n",
    "            elif task == 'taa':\n",
    "                answer = format_taa(output)\n",
    "            else:\n",
    "                raise ValueError('Task unknown!')\n",
    "        except Exception as e:\n",
    "            answer = 'Error'\n",
    "            all_responses.append(answer)\n",
    "            print('Exception at row ', index+1)\n",
    "            print(e)\n",
    "        all_results.append(answer)\n",
    "        print(index+1, answer)\n",
    "        # print(index+1)\n",
    "\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "    print('Time taken:', time_taken)\n",
    "    print('#Characters generated:', count_chars)\n",
    "    print('#Instructions failed:', instructions_failed)\n",
    "\n",
    "    # Create responses-new directory if it doesn't exist\n",
    "    output_dir = 'responses-new'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save all the responses & results to the responses-new folder\n",
    "    out_response = os.path.join(output_dir, 'SENG402_' + os.path.basename(file_path).split('.')[0] + '_' + model_name + '_response.txt')\n",
    "    out_result = os.path.join(output_dir, 'SENG402_' + os.path.basename(file_path).split('.')[0] + '_' + model_name + '_result.txt')\n",
    "\n",
    "    with open(out_response, 'w', encoding='utf-8') as f:\n",
    "        out_str = ''\n",
    "        for i in range(len(all_responses)):\n",
    "            out_str += '#####' + str(i+1) + '#####\\n'\n",
    "            out_str += all_responses[i]\n",
    "            out_str += '\\n\\n'\n",
    "        f.write(out_str)\n",
    "    with open(out_result, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(all_results))\n",
    "\n",
    "    print('------- Done --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef874d9-4a0a-4889-971b-3781410b0a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6665c28d-4d41-4b98-b150-94d12e9c3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_evaluation('datasets/cti-mcq.tsv', 'mcq', 'gpt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d94b102e-4fef-4d9e-8dc3-250b9b7edcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_evaluation('datasets/cti-rcm.tsv', 'rcm', 'gpt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3123f72-0838-4fc1-8ebe-912219909344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception at row  1\n",
      "object of type 'NoneType' has no len()\n",
      "1 Error\n",
      "Time taken: 12.952844619750977\n",
      "#Characters generated: 0\n",
      "#Instructions failed: 0\n",
      "------- Done --------\n"
     ]
    }
   ],
   "source": [
    "run_evaluation('../new-data/cti-vsp-only-2024-and-2025-SMALL.tsv', 'vsp', 'gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752819a6-5082-4e80-9501-c65720079fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_evaluation('datasets/cti-taa.tsv', 'taa', 'gpt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9be07b-6030-46c5-8442-d743875e8ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
